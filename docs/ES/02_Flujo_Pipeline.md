# Flujo del Pipeline de AnÃ¡lisis

## Diagrama del Pipeline Completo

```mermaid
flowchart TD
    %% Input
    A[ðŸ“‚ Subida Excel\n(NPS | Nota | Comentario Final)] --> B[ðŸ”Ž Parser\nreader â†’ cleaner â†’ validator â†’ normalizer]

    %% Batching
    B --> C[ðŸ“¦ Batching\nâ‰¤100 comentarios/lote]

    %% Paralelismo LLM
    C -->|Paralelo| D[ðŸ¤– LLM API Call\n(api_call.py)]
    D --> E1[ðŸŽ­ Emotions Module\n16 emociones por comentario]
    D --> E2[ðŸ©¹ Pain Points Module\nkeywords / categorÃ­as]
    D --> E3[âš ï¸ Churn Risk Module\nscore 0â€“1]
    D --> E4[ðŸ“Š NPS Module\nDetractor | Pasivo | Promotor]

    %% Merge results
    E1 & E2 & E3 & E4 --> F[ðŸ—‚ Merge Results\nengine_controller.py]

    %% Postprocess
    F --> G[ðŸ“‘ DataFrame Final\n+ columnas emo_*, pain_points, churn_risk, NPS_category]

    %% Visualization & Export
    G --> H1[ðŸ“‰ Chart Generator\n% de cada emociÃ³n (bar chart, pie opcional)]
    G --> H2[ðŸ“ˆ DistribuciÃ³n NPS]
    G --> H3[â¬‡ï¸ Report Exporter\nExcel/CSV en local-reports/]

    %% Progress/State
    B -.-> S[â± Progress Tracker\nutils/performance_monitor]
    D -.-> S
    F -.-> S
    G -.-> S
```

## Etapas Detalladas

### 1. ðŸ“‚ **Carga de Archivo**
**UbicaciÃ³n**: `components/ui_components/uploader.py`

```python
# Validaciones previas
- Formato: .xlsx, .xls, .csv
- TamaÃ±o mÃ¡ximo: 50MB  
- Columnas requeridas: ["NPS", "Nota", "Comentario Final"]
```

### 2. ðŸ”Ž **Procesamiento de Archivos**
**UbicaciÃ³n**: `core/file_processor/`

#### 2.1 Reader (`reader.py`)
```python
def read_excel(file_path: str) -> pd.DataFrame:
    # Lee Excel/CSV â†’ DataFrame
    # Detecta encoding automÃ¡ticamente
    # Maneja errores de formato
```

#### 2.2 Cleaner (`cleaner.py`) 
```python
def clean(df: pd.DataFrame) -> pd.DataFrame:
    # Elimina filas vacÃ­as
    # Trunca comentarios >2000 chars
    # Normaliza espacios en blanco
```

#### 2.3 Validator (`validator.py`)
```python 
def validate(df: pd.DataFrame) -> pd.DataFrame:
    # Verifica columnas requeridas
    # Valida rango NPS (0-10)
    # Filtra comentarios <5 chars
```

#### 2.4 Normalizer (`normalizer.py`)
```python
def normalize(df: pd.DataFrame) -> pd.DataFrame:
    # DetecciÃ³n de idioma
    # NormalizaciÃ³n UTF-8
    # Lower case opcional
```

### 3. ðŸ“¦ **Batching**
**UbicaciÃ³n**: `core/ai_engine/engine_controller.py`

```python
def _create_batches(df: pd.DataFrame) -> List[pd.DataFrame]:
    # Divide DataFrame en lotes de â‰¤100 filas
    # Optimiza para lÃ­mites de API
    # Mantiene orden original
```

### 4. ðŸ¤– **Llamadas LLM Paralelas**
**UbicaciÃ³n**: `core/ai_engine/api_call.py`

```python
class LLMApiClient:
    def analyze_batch(self, comments: List[str]) -> List[Dict]:
        # ThreadPoolExecutor para concurrencia
        # Retries automÃ¡ticos (3 intentos)
        # Fallback a modo mock si falla API
        # JSON response parsing
```

#### Prompt Template
```python
# Analiza los siguientes comentarios y devuelve para cada uno:
{
  "emotions": {
    "alegria": 0.0-1.0,
    "tristeza": 0.0-1.0,
    # ... las 16 emociones
  },
  "pain_points": ["problema1", "problema2"],
  "churn_risk": 0.0-1.0,
  "sentiment_summary": "texto libre"
}
```

### 5. ðŸŽ­ **MÃ³dulos de AnÃ¡lisis**

#### 5.1 Emotions Module (`emotion_module.py`)
```python
def analyze(llm_response: Dict) -> Dict[str, float]:
    # Extrae scores de 16 emociones
    # Valida rango [0.0, 1.0]
    # Maneja valores faltantes
```

#### 5.2 Pain Points Module (`pain_points_module.py`)  
```python
def analyze(llm_response: Dict) -> List[str]:
    # Extrae lista de pain points
    # Categoriza por tipo
    # Filtra duplicados
```

#### 5.3 Churn Module (`churn_module.py`)
```python
def analyze(llm_response: Dict) -> float:
    # Calcula riesgo de churn [0.0, 1.0]
    # Considera keywords de alto riesgo
    # Pondera con sentiment general
```

#### 5.4 NPS Module (`nps_module.py`)
```python
def analyze(llm_response: Dict, nps_score: int) -> str:
    # Categoriza NPS: detractor, passive, promoter
    # Valida consistencia con sentiment
    # Maneja valores missing
```

### 6. ðŸ—‚ **Merge de Resultados**
**UbicaciÃ³n**: `core/ai_engine/engine_controller.py`

```python
def _merge_results(original_df, results) -> pd.DataFrame:
    # Combina resultados con DataFrame original
    # Crea columnas: emo_alegria, emo_tristeza, etc.
    # AÃ±ade: pain_points, churn_risk, nps_category
    # Mantiene Ã­ndices originales
```

### 7. ðŸ“Š **VisualizaciÃ³n**
**UbicaciÃ³n**: `components/ui_components/chart_generator.py`

#### 7.1 DistribuciÃ³n de Emociones
```python
# Bar Chart Horizontal - 16 emociones individuales
# Ordenado por % (descendente)
# Color-coded: verde (positivas), rojo (negativas), azul (neutras)
```

#### 7.2 AnÃ¡lisis NPS
```python  
# Pie Chart: Promotores, Pasivos, Detractores
# CÃ¡lculo NPS Score: (Promotores - Detractores) / Total * 100
# InterpretaciÃ³n automÃ¡tica
```

#### 7.3 Riesgo de Churn
```python
# Bar Chart: Bajo, Medio, Alto riesgo
# Thresholds: 0-0.3, 0.3-0.7, 0.7-1.0
# MÃ©tricas: promedio, % alto riesgo
```

### 8. â¬‡ï¸ **ExportaciÃ³n**
**UbicaciÃ³n**: `components/ui_components/report_exporter.py`

```python
# Formatos: Excel (.xlsx), CSV (.csv), JSON (.json)  
# UbicaciÃ³n: local-reports/
# Incluye: datos raw + anÃ¡lisis + timestamp
# OpciÃ³n: solo resultados o dataset completo
```

## MÃ©tricas de Performance

### SLA Targets
- **Pipeline completo**: â‰¤10 segundos (800-1200 filas)
- **File processing**: â‰¤2 segundos
- **LLM batch**: â‰¤8 segundos
- **Chart generation**: â‰¤2 segundos
- **Data export**: â‰¤3 segundos

### Monitoreo
```python  
# utils/performance_monitor.py
@monitor.measure_time("pipeline_execution", "pipeline_execution")  
def run_pipeline(file_path: str) -> pd.DataFrame:
    # Tracking automÃ¡tico de tiempos
    # Alertas si excede SLA
    # Logging estructurado
```

## Manejo de Errores

### Niveles de Fallback
1. **API Error** â†’ Modo mock con datos simulados
2. **Parsing Error** â†’ Valores por defecto
3. **File Error** â†’ Mensaje de error claro al usuario
4. **Memory Error** â†’ Reducir batch size automÃ¡ticamente

### Logging
```python
# Todos los errores son loggeados con contexto
logger.error(f"Failed to process batch {batch_id}: {error}")
# MÃ©tricas de error por etapa
# Estado del pipeline siempre visible al usuario
```