# Personal Comment Analyzer - v2.0 Secrets Template (POST MOCK ELIMINATION)
# Copy this to secrets.toml in Streamlit Cloud and replace with your actual values
#
# ðŸš¨ CRITICAL: Mock mode has been COMPLETELY ELIMINATED
# A valid OpenAI API key is now MANDATORY for system operation
#
# ============================================================================
# CRITICAL: OPENAI API KEY - MUST BE COMPLETE AND VALID!
# ============================================================================
OPENAI_API_KEY = "sk-proj-[YOUR_COMPLETE_API_KEY_HERE]"

# ============================================================================
# API PROVIDER & TIER CONFIGURATION
# ============================================================================
API_PROVIDER = "openai"                 # "openai" or "azure"
API_TIER = "tier_1"                     # tier_1, tier_2, tier_3, tier_4, tier_5

# ============================================================================
# AI ENGINE CONFIGURATION (Enhanced v2.0)
# ============================================================================

# OpenAI Model Settings
MODEL_NAME = "gpt-4o-mini"              # Cost-effective model
MAX_TOKENS_PER_CALL = "12000"           # Max tokens per API call
MAX_TOKENS_PER_REQUEST = "12000"        # Max tokens per request

# Batch Processing (Production Optimized)
MAX_BATCH_SIZE = "30"                   # Comments per batch
MAX_WORKERS = "1"                       # Streamlit-safe: Sequential only

# Token Estimation (Smart Batching)
AVG_TOKENS_PER_COMMENT = "150"          # Average tokens per comment
PROMPT_TOKENS = "800"                   # System prompt overhead
MAX_COMMENT_LENGTH = "2000"             # Max characters per comment
MIN_COMMENT_LENGTH = "5"                # Min characters per comment

# ============================================================================
# RATE LIMITING & PERFORMANCE
# ============================================================================

# Rate Limits (Conservative Production)
REQUESTS_PER_MINUTE = "60"              # API requests per minute
TOKENS_PER_MINUTE = "150000"            # API tokens per minute

# Performance Targets
PERFORMANCE_SLA_TARGET_SECONDS = "10"   # Target processing time
PERFORMANCE_SLA_PERCENTILE = "50"       # Performance tracking

# Retry Configuration
MAX_RETRIES = "3"                       # API call retries
RETRY_DELAY_SECONDS = "0.5"             # Base retry delay

# ============================================================================
# NPS INFERENCE CONFIGURATION (New in v2.0)
# ============================================================================

# NPS Inference Engine (Post-AI Processing)
ENABLE_NPS_INFERENCE = "true"           # Emotion-based NPS calculation
NPS_INFERENCE_CONFIDENCE_THRESHOLD = "0.5"  # Minimum confidence
NPS_INFERENCE_METHOD = "emotion_weighted"    # Algorithm method

# Emotion Weights (Expert Tuning)
EMOTION_WEIGHT_ENTUSIASMO = "2.8"       # Strongest positive
EMOTION_WEIGHT_ENOJO = "-3.0"           # Strongest negative
EMOTION_WEIGHT_GRATITUD = "2.5"         # Loyalty signal
EMOTION_WEIGHT_FRUSTRACION = "-2.7"     # Dissatisfaction

# ============================================================================
# ENHANCED DATA PROCESSING (Smart Parsing)
# ============================================================================

# Smart NPS Parser
ENABLE_SMART_NPS_PARSING = "true"       # Text-to-NPS conversion
ENABLE_SCALE_CONVERSION = "true"        # "/5", "/10", "%" conversion
ENABLE_SENTIMENT_NPS_MAPPING = "true"   # Text sentiment mapping

# Response Parser (JSON Repair)
ENABLE_JSON_REPAIR = "true"             # Auto-repair malformed JSON
ENABLE_RESPONSE_NORMALIZATION = "true"  # Normalize response structure
JSON_EXTRACTION_STRATEGIES = "5"        # Extraction strategy count

# ============================================================================
# MONITORING & VALIDATION
# ============================================================================

# Usage Monitoring
ENABLE_USAGE_MONITORING = "true"        # Real-time usage tracking
USAGE_WARNING_THRESHOLD = "70"          # Warning at 70%
USAGE_CRITICAL_THRESHOLD = "85"         # Critical at 85%

# Performance Monitoring
ENABLE_PERFORMANCE_MONITORING = "true"  # Track performance
LOG_PERFORMANCE_METRICS = "true"        # Log detailed metrics

# External Validation Logging (New in v2.0)
ENABLE_PIPELINE_LOGGING = "true"        # External validation logs
PIPELINE_LOG_LEVEL = "INFO"             # Validation log level
PIPELINE_LOG_RETENTION_HOURS = "72"     # Auto-cleanup after 72h
ENABLE_LIVE_REPORTS = "true"            # Live markdown reports

# ============================================================================
# FEATURE FLAGS (Mock Mode ELIMINATED)
# ============================================================================

# Core Features
ENABLE_RATE_LIMIT_MONITORING = "true"   # Intelligent rate limiting
ENABLE_DYNAMIC_BATCH_SIZING = "true"    # Dynamic batch adjustment
ENABLE_TOKEN_USAGE_LOGGING = "true"     # Token consumption logging

# UI Features
ENABLE_ADVANCED_CHARTS = "true"         # Advanced visualizations
ENABLE_EXPORT = "true"                  # File export functionality
ENABLE_BATCH_PROGRESS = "true"          # Batch progress display

# Development Features (Production Safe)
ENABLE_DEBUG_MODE = "false"             # Debug mode (keep false)
ENABLE_PERFORMANCE_TESTING = "false"    # Performance endpoints
ENABLE_PIPELINE_LOGGING = "true"        # External validation logging

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================

# Application Logging
LOG_LEVEL = "INFO"                      # Logging verbosity
ENABLE_DEBUG_LOGGING = "false"          # Debug logs
LOG_TO_FILE = "true"                    # Log to file
LOG_TO_CONSOLE = "true"                 # Log to console

# Validation Logging (10-Level Granular)
LOG_L1_API_VALIDATION = "true"          # API configuration
LOG_L2_DATA_INGESTION = "true"          # File reading
LOG_L3_PREPROCESSING = "true"           # Data cleaning
LOG_L4_API_EXECUTION = "true"           # API calls
LOG_L5_RESPONSE_PROCESSING = "true"     # JSON parsing
LOG_L6_NPS_INFERENCE = "true"           # NPS inference
LOG_L7_DATA_TRANSFORMATION = "true"     # Chart formatting
LOG_L8_CHART_VALIDATION = "true"        # Chart system
LOG_L9_EXPORT_VALIDATION = "true"       # Export system
LOG_L10_PIPELINE_SUMMARY = "true"       # End-to-end summary

# ============================================================================
# DATA PROCESSING & VALIDATION
# ============================================================================

# File Processing
MAX_FILE_SIZE_MB = "50"                 # Upload size limit
SUPPORTED_FILE_TYPES = ".xlsx,.xls,.csv"  # Supported formats

# Data Validation
VALIDATE_INPUT = "true"                 # Input validation
SANITIZE_OUTPUTS = "true"               # Output sanitization
ENABLE_FILE_TYPE_VALIDATION = "true"    # File type validation

# Data Limits
MAX_ROWS_PER_FILE = "50000"             # Max rows per file
MIN_ROWS_PER_FILE = "1"                 # Min rows per file

# ============================================================================
# LANGUAGE & LOCALIZATION
# ============================================================================

# Language Support
SUPPORTED_LANGS = "es,gn,en"            # Supported languages
DEFAULT_LANG = "es"                     # Default language

# ============================================================================
# DEPLOYMENT ENVIRONMENT
# ============================================================================

# Environment Settings
ENVIRONMENT = "production"              # Environment type
DEPLOYMENT_TIMESTAMP = "2025-09-13"     # Deployment date
APP_VERSION = "2.0.0"                  # Application version

# Resource Limits (Streamlit Cloud)
MAX_CONCURRENT_USERS = "50"            # Expected concurrent users
MEMORY_LIMIT_MB = "1024"               # Memory allocation
CPU_LIMIT = "1.0"                      # CPU allocation

# ============================================================================
# STREAMLIT CLOUD DEPLOYMENT CHECKLIST v2.0
# ============================================================================
#
# BEFORE DEPLOYMENT:
# âœ… Copy this template to Streamlit Cloud secrets
# âœ… Replace OPENAI_API_KEY with your complete API key
# âœ… Set API_TIER to match your OpenAI account tier
# âœ… Verify ENVIRONMENT = "production"
# âœ… Confirm all ENABLE_* flags are set correctly
#
# AFTER DEPLOYMENT:
# âœ… Test with real data to verify no 401 errors
# âœ… Check external logs: local-reports/pipeline-validation/
# âœ… Verify NPS inference working (missing values filled)
# âœ… Confirm charts display properly
# âœ… Test export functionality
#
# MONITORING:
# - External validation logs auto-generate in local-reports/
# - Use log_cleanup.py utilities for log management
# - Live reports available during pipeline execution
#
# ðŸš¨ BREAKING CHANGE: Mock mode eliminated - API key is mandatory